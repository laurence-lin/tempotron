{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Python_coding.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPnVNYwyAkJrVKY8xU1yS1o",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/laurence-lin/tempotron/blob/master/tempotron.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jODgGqlTlQPy",
        "outputId": "7495e24f-de6c-43b0-9641-14339e6ca04b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import csv\n",
        "import os\n",
        "import time\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n",
        "import tensorflow as tf\n",
        "\n",
        "print('Library imported.')\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Library imported.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-pz7dpbnCzP"
      },
      "source": [
        "\n",
        "# Input value encoding: Gaussian receptive field\n",
        "gauss_neuron = 12  # each input value is encoded by 12 gaussian neurons\n",
        "center = np.ones((gauss_neuron, 1))\n",
        "width = 1/15\n",
        "\n",
        "# let the value range equal in each feautres, thus gaussian encoding center for each feature is the same\n",
        "for i in range(len(center)): # let X_max=1, x_min=0. Center for each feature=i/(n - 1)\n",
        "  center[i] = (2*i-3)/20  # Center of gaussian shift from left to right\n",
        "\n",
        "x = np.arange(0, 1, 0.0001) # input variable resolution in gaussian receptive field\n",
        "\n",
        "num_features = 4\n",
        "gauss_recpt_field = np.zeros((gauss_neuron, len(x))) # gaussian receptive field for input stimulate response\n",
        "spike_time = np.zeros((gauss_neuron, num_features)) # 48 gaussian encoding neurons for 4 input features\n",
        "\n",
        "# Define gaussian receptive field for input variables entries\n",
        "for i in range(gauss_neuron):\n",
        "  gauss_recpt_field[i, :] = np.exp( -(x-center[i])**2/(2*width*width) ) # different shift for each gaussian function\n",
        "\n",
        "\n",
        "def gauss_response(inputs):\n",
        "  # input: shape [1, features] \n",
        "  # output: shape [gaussian neurons*features] spiking time\n",
        "  \n",
        "  for i in range(num_features):\n",
        "    # for each input[i]\n",
        "    for j in range(gauss_neuron):\n",
        "      spike_time[j, i] = gauss_recpt_field[j, inputs[i]] # input feature enter the gaussian entry, recieve response\n",
        "\n",
        "  spikes = []\n",
        "  for i in range(spike_time.shape[1]):\n",
        "    spikes.extend(spike_time[:, i])\n",
        "\n",
        "  return np.array(spikes)\n",
        "\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jd9M-r52N1-N",
        "outputId": "c3928e3e-0b5d-4ee2-ba07-954c0e0ba2d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        }
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data', header = None)\n",
        "\n",
        "encoder = LabelEncoder()\n",
        "df.iloc[:, 4] = encoder.fit_transform(df.iloc[:, 4])\n",
        "print(df.head())\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# shuffle data\n",
        "df = df.sample(frac=1).reset_index(drop = True)\n",
        "print(df.head())\n",
        "\n",
        "X = df.iloc[:, 0:4]\n",
        "y = df.iloc[:, -1]\n",
        "\n",
        "gauss_neurons = gauss_neuron*num_features\n",
        "\n",
        "# Normalization\n",
        "scaler = MinMaxScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# There are 10000 entries in each gaussian function\n",
        "X = (X*10000).astype(int) # meet the index of gaussian receptive field, drop the fourth decimal\n",
        "X[X == 10000] = 9999 # convert all input value indexing to gaussian matrix entry\n",
        "input_spike = np.zeros((X.shape[0], gauss_neurons)) # spike time in [0, 1]\n",
        "\n",
        "for i in range(X.shape[0]):\n",
        "  input_spike[i, :] = gauss_response(X[i, :])\n",
        "\n",
        "input_spike[input_spike < 0.1] = 0  # set activate value < 0.1 to zero\n",
        "input_spike = np.around(100*(1 - input_spike)) # convert actiate value to 0~100 timing, round the decimals\n",
        "#Adjust t = 0 firing to t = 1\n",
        "input_spike[input_spike == 0] = 1\n",
        "\n",
        "\n",
        "x_train, x_valid, y_train, y_valid = train_test_split(input_spike, y, test_size = 0.2, stratify = y)\n",
        "y_train, y_valid = y_train.values, y_valid.values"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     0    1    2    3  4\n",
            "0  5.1  3.5  1.4  0.2  0\n",
            "1  4.9  3.0  1.4  0.2  0\n",
            "2  4.7  3.2  1.3  0.2  0\n",
            "3  4.6  3.1  1.5  0.2  0\n",
            "4  5.0  3.6  1.4  0.2  0\n",
            "     0    1    2    3  4\n",
            "0  5.6  3.0  4.5  1.5  1\n",
            "1  5.0  3.5  1.3  0.3  0\n",
            "2  6.0  3.4  4.5  1.6  1\n",
            "3  5.4  3.7  1.5  0.2  0\n",
            "4  6.1  2.8  4.7  1.2  1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6YBew-OZC4r",
        "outputId": "b01170ee-0a23-4572-d1c3-d16dec4c8bd0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Start training\n",
        "\n",
        "def heavyside(t, t_i):\n",
        "  if (t - t_i) >= 0:\n",
        "    return 1\n",
        "  elif (t - t_i) < 0:\n",
        "    return 0\n",
        "\n",
        "def K_res(t, t_i):\n",
        "  time = np.arange(0, 101, 1)\n",
        "  tou_m = 15\n",
        "  tou_s = tou_m/4\n",
        "  V_0 = (np.exp(-(time)/tou_m) - np.exp(-(time)/tou_s)).max()  #normalization factor: divide the K() response by maximum value\n",
        "  response = ( np.exp(-(t-t_i)/tou_m) - np.exp(-(t-t_i)/tou_s) )*heavyside(t, t_i)/V_0\n",
        "  return response\n",
        "\n",
        "\n",
        "iterations = 50\n",
        "num_class = 3\n",
        "V = np.zeros((num_class, 100)) # potential of each output neuron\n",
        "V_rest = 0\n",
        "weight = np.random.random((gauss_neurons, num_class)) # connections btw input neuron and output neuron(here use single synaptic for simplicity)\n",
        "threshold = 1 # set threshold: try and error\n",
        "T = 100    # time encoding window\n",
        "firing_time = np.zeros((gauss_neurons)) # time-to-first-spike for all gaussian neurons\n",
        "Response = np.zeros((gauss_neurons))  # K(t-t_i) response for each gaussian neurons\n",
        "lr = 0.005\n",
        "tou_m = 15\n",
        "time = np.arange(1, T+1)\n",
        "accuracy = np.zeros((iterations))\n",
        "\n",
        "def train():  \n",
        "\n",
        "   for iterate in range(iterations):\n",
        "\n",
        "      # Check the accuracy after training each classifier\n",
        "      correct = 0 \n",
        "      val_predict = np.zeros((y_valid.shape))\n",
        "      for valid_sample in range(y_valid.shape[0]):\n",
        "        t_max = T*np.ones((num_class), dtype = np.int8) # default firing time: all neuron's maximum firing time at 100ms\n",
        "        max_state = np.zeros((num_class)) # max potential state of each output neuron\n",
        "        # Go through a time window, observe the firing history\n",
        "        for t in range(T):\n",
        "          for neuron in range(gauss_neurons):\n",
        "            Response[neuron] = K_res(t, x_valid[valid_sample, neuron])\n",
        "\n",
        "          #calculate PSP for output neuron \n",
        "          for out_id in range(num_class):\n",
        "            V[out_id, t] = np.matmul(Response,weight[:, out_id]) + V_rest\n",
        "\n",
        "        # Find the firing timing t_max\n",
        "        for out_id in range(num_class):\n",
        "          fire_time = np.where((V > threshold)[out_id, :])[0]\n",
        "          if len(fire_time) > 0: # set firing time between 1 to 100\n",
        "            max_state[out_id] = fire_time[0] + 1\n",
        "            t_max[out_id] = fire_time[0] + 1\n",
        "            t_max[out_id] = t_max[out_id].astype(int)\n",
        "          else:\n",
        "            max_state[out_id] = T\n",
        "          \n",
        "          if t_max[out_id] < T: # if output neuron fires\n",
        "            V[out_id, t_max[out_id]:] = V[out_id, t_max[out_id]]*np.exp((time[t_max[out_id]:]-time[t_max[out_id]])/tou_m)\n",
        "        # We only need t_max for prediction?\n",
        "        pred_class = np.argmin(t_max)\n",
        "        val_predict[valid_sample] = pred_class\n",
        "\n",
        "      acc = accuracy_score(y_valid, val_predict)\n",
        "      print('Validation accuaracy at iteration {}: {}'.format(str(iterate+1), acc))\n",
        "\n",
        "      # Training\n",
        "      for sample in range(x_train.shape[0]):\n",
        "        t_max = 100*np.ones((num_class), dtype = np.int8)\n",
        "        max_state = np.zeros((num_class))\n",
        "        for t in range(T):\n",
        "          for neuron in range(gauss_neurons):\n",
        "            Response[neuron] = K_res(t, x_train[sample, neuron])\n",
        "          for out_id in range(num_class):\n",
        "            V[out_id, t] = np.matmul(Response,weight[:, out_id]) + V_rest\n",
        "\n",
        "        # Find the firing timing t_max\n",
        "        for out_id in range(num_class):\n",
        "          for timing in range(T):\n",
        "            if V[out_id, timing] >= threshold:\n",
        "              t_max[out_id] = timing\n",
        "              max_state[out_id] = V[out_id, timing]\n",
        "              break\n",
        "          \n",
        "          if t_max[out_id] < T: # if output neuron fires\n",
        "            V[out_id, t_max[out_id]:] = V[out_id, t_max[out_id]]*np.exp((time[t_max[out_id]:]-time[t_max[out_id]])/tou_m)\n",
        "\n",
        "        pred_class = np.argmin(t_max)\n",
        "        # Modify weight when error occurs: stochastic learning\n",
        "        target = y_train[sample] # if target class != predict class, modify the weight\n",
        "        if pred_class != target:\n",
        "          for out_id in range(num_class):\n",
        "            if out_id == target:\n",
        "              if max_state[out_id] < threshold: # if the neuron supposed to fire did not fire\n",
        "                for neuron in range(gauss_neurons):\n",
        "                  if x_train[sample, neuron] < t_max[out_id]: # for input neuron that contribute to the firing\n",
        "                    # enhance the weight connection to the output neuron corresponding to target class\n",
        "                    weight[neuron, out_id] += lr*K_res(t_max[out_id], x_train[sample, neuron])\n",
        "\n",
        "            elif out_id != target:\n",
        "              if max_state[out_id] >= threshold: # if neuron shouldn't fired are erupted to fire\n",
        "                for neuron in range(gauss_neurons):\n",
        "                  if x_train[sample, neuron] < t_max[out_id]:\n",
        "                    # for input neuron contribute to the spike, inhibit the firing\n",
        "                    \n",
        "                    weight[neuron, out_id] -= lr*K_res(t_max[out_id], x_train[sample, neuron])\n",
        "                    \n",
        "\n",
        "        # Even if predict class is correct, if the output neuron other than target class is evoked,\n",
        "        # we should inhibit the firing of these neurons\n",
        "        elif pred_class == target:\n",
        "          for out_id in range(num_class):\n",
        "            if out_id != target:\n",
        "              if max_state[out_id] >= threshold:\n",
        "                for neuron in range(gauss_neurons):\n",
        "                  if x_train[sample, neuron] < t_max[out_id]:\n",
        "                    weight[neuron, out_id] -= lr*K_res(t_max[out_id], x_train[sample, neuron])\n",
        "\n",
        "      # Check training accuracy\n",
        "      train_predict = np.zeros(y_train.shape)\n",
        "      for train_sample in range(x_train.shape[0]):\n",
        "        t_max = T*np.ones((num_class), dtype = np.int8) # default firing time: all neuron's maximum firing time at 100ms\n",
        "        max_state = np.zeros((num_class)) # max potential state of each output neuron\n",
        "        # Go through a time window, observe the firing history\n",
        "        for t in range(T):\n",
        "          for neuron in range(gauss_neurons):\n",
        "            Response[neuron] = K_res(t, x_train[train_sample, neuron])\n",
        "\n",
        "          #calculate PSP for output neuron \n",
        "          for out_id in range(num_class):\n",
        "            V[out_id, t] = np.matmul(Response,weight[:, out_id]) + V_rest\n",
        "\n",
        "        # Find the firing timing t_max\n",
        "        for out_id in range(num_class):\n",
        "          for timing in range(T):\n",
        "            if V[out_id, timing] >= threshold:\n",
        "              t_max[out_id] = timing\n",
        "              max_state[out_id] = V[out_id, timing]\n",
        "              break\n",
        "          \n",
        "          if t_max[out_id] < T: # if output neuron fires\n",
        "            V[out_id, t_max[out_id]:] = V[out_id, t_max[out_id]]*np.exp((time[t_max[out_id]:]-time[t_max[out_id]])/tou_m)\n",
        "\n",
        "        # We only need t_max for prediction?\n",
        "        pred_class = np.argmin(t_max)\n",
        "        train_predict[train_sample] = pred_class\n",
        "\n",
        "      acc = accuracy_score(y_train, train_predict)\n",
        "      print('Training accuaracy at iteration {}: {}'.format(str(iterate+1), acc))\n",
        "\n",
        "      \n",
        "\n",
        "train()       \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation accuaracy at iteration 1: 0.36666666666666664\n",
            "Training accuaracy at iteration 1: 0.31666666666666665\n",
            "Validation accuaracy at iteration 2: 0.4\n",
            "Training accuaracy at iteration 2: 0.4166666666666667\n",
            "Validation accuaracy at iteration 3: 0.5\n",
            "Training accuaracy at iteration 3: 0.475\n",
            "Validation accuaracy at iteration 4: 0.5\n",
            "Training accuaracy at iteration 4: 0.5583333333333333\n",
            "Validation accuaracy at iteration 5: 0.5\n",
            "Training accuaracy at iteration 5: 0.6\n",
            "Validation accuaracy at iteration 6: 0.5\n",
            "Training accuaracy at iteration 6: 0.6666666666666666\n",
            "Validation accuaracy at iteration 7: 0.5666666666666667\n",
            "Training accuaracy at iteration 7: 0.725\n",
            "Validation accuaracy at iteration 8: 0.6666666666666666\n",
            "Training accuaracy at iteration 8: 0.7583333333333333\n",
            "Validation accuaracy at iteration 9: 0.7\n",
            "Training accuaracy at iteration 9: 0.7916666666666666\n",
            "Validation accuaracy at iteration 10: 0.7666666666666667\n",
            "Training accuaracy at iteration 10: 0.8166666666666667\n",
            "Validation accuaracy at iteration 11: 0.7666666666666667\n",
            "Training accuaracy at iteration 11: 0.8416666666666667\n",
            "Validation accuaracy at iteration 12: 0.7666666666666667\n",
            "Training accuaracy at iteration 12: 0.8666666666666667\n",
            "Validation accuaracy at iteration 13: 0.7666666666666667\n",
            "Training accuaracy at iteration 13: 0.875\n",
            "Validation accuaracy at iteration 14: 0.7666666666666667\n",
            "Training accuaracy at iteration 14: 0.8916666666666667\n",
            "Validation accuaracy at iteration 15: 0.8\n",
            "Training accuaracy at iteration 15: 0.8916666666666667\n",
            "Validation accuaracy at iteration 16: 0.7666666666666667\n",
            "Training accuaracy at iteration 16: 0.9\n",
            "Validation accuaracy at iteration 17: 0.7333333333333333\n",
            "Training accuaracy at iteration 17: 0.8916666666666667\n",
            "Validation accuaracy at iteration 18: 0.7666666666666667\n",
            "Training accuaracy at iteration 18: 0.8916666666666667\n",
            "Validation accuaracy at iteration 19: 0.7666666666666667\n",
            "Training accuaracy at iteration 19: 0.9\n",
            "Validation accuaracy at iteration 20: 0.7666666666666667\n",
            "Training accuaracy at iteration 20: 0.9083333333333333\n",
            "Validation accuaracy at iteration 21: 0.7666666666666667\n",
            "Training accuaracy at iteration 21: 0.9083333333333333\n",
            "Validation accuaracy at iteration 22: 0.7666666666666667\n",
            "Training accuaracy at iteration 22: 0.9083333333333333\n",
            "Validation accuaracy at iteration 23: 0.7666666666666667\n",
            "Training accuaracy at iteration 23: 0.9083333333333333\n",
            "Validation accuaracy at iteration 24: 0.7666666666666667\n",
            "Training accuaracy at iteration 24: 0.9166666666666666\n",
            "Validation accuaracy at iteration 25: 0.7666666666666667\n",
            "Training accuaracy at iteration 25: 0.9166666666666666\n",
            "Validation accuaracy at iteration 26: 0.7666666666666667\n",
            "Training accuaracy at iteration 26: 0.9166666666666666\n",
            "Validation accuaracy at iteration 27: 0.7666666666666667\n",
            "Training accuaracy at iteration 27: 0.9166666666666666\n",
            "Validation accuaracy at iteration 28: 0.8333333333333334\n",
            "Training accuaracy at iteration 28: 0.9166666666666666\n",
            "Validation accuaracy at iteration 29: 0.8333333333333334\n",
            "Training accuaracy at iteration 29: 0.9166666666666666\n",
            "Validation accuaracy at iteration 30: 0.8333333333333334\n",
            "Training accuaracy at iteration 30: 0.925\n",
            "Validation accuaracy at iteration 31: 0.8333333333333334\n",
            "Training accuaracy at iteration 31: 0.9333333333333333\n",
            "Validation accuaracy at iteration 32: 0.8333333333333334\n",
            "Training accuaracy at iteration 32: 0.9333333333333333\n",
            "Validation accuaracy at iteration 33: 0.8333333333333334\n",
            "Training accuaracy at iteration 33: 0.9333333333333333\n",
            "Validation accuaracy at iteration 34: 0.8333333333333334\n",
            "Training accuaracy at iteration 34: 0.9333333333333333\n",
            "Validation accuaracy at iteration 35: 0.8333333333333334\n",
            "Training accuaracy at iteration 35: 0.9416666666666667\n",
            "Validation accuaracy at iteration 36: 0.8333333333333334\n",
            "Training accuaracy at iteration 36: 0.95\n",
            "Validation accuaracy at iteration 37: 0.8333333333333334\n",
            "Training accuaracy at iteration 37: 0.95\n",
            "Validation accuaracy at iteration 38: 0.8333333333333334\n",
            "Training accuaracy at iteration 38: 0.9416666666666667\n",
            "Validation accuaracy at iteration 39: 0.8333333333333334\n",
            "Training accuaracy at iteration 39: 0.9333333333333333\n",
            "Validation accuaracy at iteration 40: 0.8333333333333334\n",
            "Training accuaracy at iteration 40: 0.9333333333333333\n",
            "Validation accuaracy at iteration 41: 0.8333333333333334\n",
            "Training accuaracy at iteration 41: 0.9333333333333333\n",
            "Validation accuaracy at iteration 42: 0.8333333333333334\n",
            "Training accuaracy at iteration 42: 0.9333333333333333\n",
            "Validation accuaracy at iteration 43: 0.8333333333333334\n",
            "Training accuaracy at iteration 43: 0.9333333333333333\n",
            "Validation accuaracy at iteration 44: 0.8333333333333334\n",
            "Training accuaracy at iteration 44: 0.9333333333333333\n",
            "Validation accuaracy at iteration 45: 0.8666666666666667\n",
            "Training accuaracy at iteration 45: 0.9333333333333333\n",
            "Validation accuaracy at iteration 46: 0.8666666666666667\n",
            "Training accuaracy at iteration 46: 0.9333333333333333\n",
            "Validation accuaracy at iteration 47: 0.8666666666666667\n",
            "Training accuaracy at iteration 47: 0.9333333333333333\n",
            "Validation accuaracy at iteration 48: 0.8333333333333334\n",
            "Training accuaracy at iteration 48: 0.9416666666666667\n",
            "Validation accuaracy at iteration 49: 0.8666666666666667\n",
            "Training accuaracy at iteration 49: 0.9416666666666667\n",
            "Validation accuaracy at iteration 50: 0.8666666666666667\n",
            "Training accuaracy at iteration 50: 0.9416666666666667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-mFdxdQHaJ85",
        "outputId": "0632b281-f05e-41e5-bb60-a4201d70ba06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "x = K_res(100, 30)\n",
        "x"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.019903774783916143"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oe81z_tg3cII"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}